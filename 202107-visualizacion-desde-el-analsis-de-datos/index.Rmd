---
title: "{20:00}§2v|0i|2s|3u|2a|1l|0[-]i|1z|2a|1c|3[++]i|2o|1n|2{14jul}[16°c[10°c]"
subtitle: "desde el análsis de datos"
author: "<br>Joshua Kunst<br>@jbkunst"
# institute: ""
# date: "2020/07/12 (actualizado: `r Sys.Date()`)"
output:
  xaringan::moon_reader:
    css: [xaringan-themer.css]
    # css: [metropolis, xaringan-themer.css]
    # css: [metropolis, metro-custom.css]
    lib_dir: libs
    nature:
      ratio: "16:9"
      titleSlideClass: ["left", "middle", "my-title"]
      highlightStyle: github
editor_options: 
  chunk_output_type: console
---

# Hola!

### Soy Joshua

```{r parameters, include=FALSE, warning=FALSE}
MAIN_COLOR <- "#47475C"
BCKGRN_COLOR <- "#FFFAFA" # snow white
# MAIN_FONT <- "Lato"
# MAIN_FONT <- "Alegreya Sans SC"
MAIN_FONT <- "IBM Plex Sans"

```

```{r, include=FALSE, warning=FALSE}
library(tableHTML)

mycss <- make_css(
  list('.remark-slide-content',
       c('background-color', 'border-top'),
       c(BCKGRN_COLOR, paste("80px solid", MAIN_COLOR))),
   file = here::here("202107-visualizacion-desde-el-analsis-de-datos/metro-custom.css")
  )
```

```{css, echo=FALSE}
@import url('https://fonts.cdnfonts.com/css/datalegreya');

.title-slide {
  background-image: url(title-slide-bg.png);
  background-size: cover;
}

.title-slide > h1,
.title-slide > h2,
.remark__tile-view__header {
  font-family: 'Datalegreya', sans-serif;
}

.title-slide > h1,
.remark__tile-view__header {
  font-size: 6em;
}

.title-slide > h1,
.title-slide > h2 {
  padding: 0px;
  margin: 0px;
}

body {
  font-family: -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Helvetica, Arial, sans-serif, "Apple Color Emoji", "Segoe UI Emoji", "Segoe UI Symbol";
}
```

```{r setup-xaringan, include=FALSE, warning=FALSE}
library(xaringanthemer)

style_mono_accent(
  base_color       = MAIN_COLOR,
  background_color = BCKGRN_COLOR,
  # header_font_google = google_font("Alegreya Sans SC", 100),
  header_font_google = google_font(MAIN_FONT, 100),
  text_font_google   = google_font("Roboto"),
  code_font_google   = google_font("Fira Mono"),
  base_font_size = "20px",
  header_h1_font_size = "2.0rem", # "2.75rem",
  header_h3_font_size = "1.5rem", # "2.75rem",
  outfile = here::here("202107-visualizacion-desde-el-analsis-de-datos/xaringan-themer.css")
)

xaringanExtra::use_scribble(pen_color = MAIN_COLOR) # press S
xaringanExtra::use_tile_view()                      # press O
xaringanExtra::use_webcam()                         # press W
xaringanExtra::use_animate_all("fade")
xaringanExtra::use_freezeframe() # for GIFs!
# xaringanExtra::use_progress_bar(color = "red", location = "bottom", height = "30px")
```


```{r setup, include=FALSE, warning=FALSE}
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  echo = FALSE,
  dev = "svg",
  cache = FALSE,
  fig.path = "imgs/knitr-img-",
  fig.align = "center",
  fig.width = 10,
  fig.height = 5
)

library(tidyverse)
library(kunstomverse)
library(patchwork)
library(showtext)

font_add_google(MAIN_FONT, "main_font")

showtext_auto()

theme_set(
  kunstomverse::theme_knst(
    base_size       = 10,
    axis_title_size = 8,
    base_family     = "main_font",
    plot_margin     = ggplot2::margin(10, 10, 10, 10),
    plot_title_face = "plain", 
    subtitle_face = "plain"
    ) +
    theme(
      plot.title = element_text(face = "plain"),
      plot.background = element_rect(fill = BCKGRN_COLOR, colour = NA),
      legend.key.width = unit(1.5, "cm")
    )
  )
```


---

# Visualización

Como parte del análisis de datos

<br>

```{r out.width="80%"}
# knitr::include_graphics(here::here("202107-visualizacion-desde-el-analsis-de-datos/imgs/data-science.svg"))
 knitr::include_graphics("imgs/data-science.svg")
```

---

# Visualización **de datos**

Herramienta que codifica información a travéz...

```{r out.width="60%", fig.align='center'}
# knitr::include_graphics(here::here("202107-visualizacion-desde-el-analsis-de-datos/imgs/data-viz.jpg"))
knitr::include_graphics("imgs/data-viz.jpg")
```

---

class: center middle
background-image: url(https://wallpaperplay.com/walls/full/8/b/9/112119.jpg)

# Ejemplo 

---

# Datos

```{r legodata, cache=TRUE}
legos <- read_csv("https://raw.githubusercontent.com/seankross/lego/master/data-tidy/legosets.csv") %>% 
  mutate(year2 = floor(Year/10)*10) %>% 
  sample_n(3000)
```

```{r out.width="90%", fig.align='center'}
# knitr::include_graphics(here::here("202107-visualizacion-desde-el-analsis-de-datos/imgs/data-viz.jpg"))
knitr::include_graphics("imgs/legoscsv.png")
```

---

# Explorar

¿Qué vemos?

```{r}
ggplot(legos) + 
  geom_point(aes(Pieces, USD_MSRP), alpha = 0.25, size = 1) +
  scale_y_sqrt(labels = scales::dollar, limits = c(1, 300)) +
  scale_x_sqrt(labels = scales::comma, limits = c(1, 2000)) +
  labs(title = "Precio segun piezas", x = "Piezas", y = "Precio USD")
```

---

# Intento inicial

Codificamos mayor información

```{r}
ggplot(legos) + 
  geom_point(aes(Pieces, USD_MSRP, size = Minifigures, color = year2), alpha = 0.5) +
  scale_y_sqrt(labels = scales::dollar, limits = c(1, 300)) +
  scale_x_sqrt(labels = scales::comma, limits = c(1, 2000)) +
  scale_size(name = "Piezas") +
  scale_color_viridis_c(name = "", option = "B", breaks = c(1970, 1980, 1990, 2000, 2010)) +
  labs(title = "Precio segun piezas", x = "Piezas", y = "Precio USD")
```

---

# Otro intento

Cada visualización cuenta una historia distinta...

```{r}
fmt_dec <- function(x) {
  
  if(as.numeric(x) == 2000) {
    out <- x
  } else {
    out <- paste(str_extract(x, "[0-9]{2}$"), "'s")
  }
  
  out
  
}

fmt_dec <- Vectorize(fmt_dec)

ggplot(legos) +
  geom_jitter(aes(factor(year2), USD_MSRP, size = Pieces, color = Year), alpha = 0.5, width = 0.25) +
  scale_color_viridis_c(option = "A", breaks = c(1970, 1990, 2010), guide = "none") + 
  scale_size(name = "Piezas") +
  scale_y_continuous(name = "Precio USD", labels = scales::dollar, limits = c(0, 300)) + 
  scale_x_discrete(name = "Década", labels = fmt_dec) +
  labs(title = "Precios por década")
```

---

class: center middle

# Poniendo en práctica


---

# Datos

Ingresos de usuarios a estaciones de metros cada media hora

```{r metrodata, cache=TRUE, include=FALSE}
data <- read_delim(url("https://tinyurl.com/data-metro-scl"), delim = ";")
data <- data %>% 
  filter(!str_detect(paraderosubida, "[0-9]+-[0-9]")) %>% 
  filter(paraderosubida != "-") %>% 
  filter(lubridate::hour(mediahora) > 0) 

data <- data %>% 
  mutate(mediahora = lubridate::as_datetime(mediahora))

year(data$mediahora) <- 2015

data
```

```{r out.width="45%", fig.align='center'}
# knitr::include_graphics(here::here("202107-visualizacion-desde-el-analsis-de-datos/imgs/data-viz.jpg"))
knitr::include_graphics("imgs/metrocsv.png")
```


---

# Partamos por lo simple

```{r}
dalcantara <- data %>% 
  filter(paraderosubida == "ALCANTARA")

ggplot(dalcantara) +
  geom_point(aes(subidas_laboral_promedio, mediahora, color = paraderosubida), size = 1.5) +
  scale_y_datetime(date_labels = "%R") +
  scale_x_continuous(labels = comma) +
  scale_color_viridis_d(guide = "none")
```

---

# ¿Simple?

Es bueno equivocarse

```{r}
ggplot(dalcantara) +
  geom_path(aes(subidas_laboral_promedio, mediahora, color = paraderosubida), size = 1.5) +
  scale_y_datetime(date_labels = "%R") +
  scale_x_continuous(labels = comma) +
  scale_color_viridis_d(guide = "none")
```

---

# Ahora sí!!

Hay ciertas convenciones que no es malo seguir...

```{r}
ggplot(dalcantara) +
  geom_path(aes(mediahora, subidas_laboral_promedio, color = paraderosubida), size = 1.5) +
  scale_x_datetime(date_labels = "%R") +
  scale_y_continuous(labels = comma) +
  scale_color_viridis_d(guide = "none")
```

---

# Combinemos

Importante observar patrones/relaciones en los datos.

```{r}
d1 <- data %>% 
  filter(paraderosubida %in% c("PLAZA MAIPU", "LAGUNA SUR"))

c <- d1 %>% 
  spread(paraderosubida, subidas_laboral_promedio) %>%
  filter(complete.cases(.)) %>% 
  select(-1) %>%
  as.matrix() %>% 
  cor() %>% 
  as.vector() %>% 
  nth(2)

p1 <- ggplot(d1) +
  geom_line(
    aes(mediahora, subidas_laboral_promedio, color = paraderosubida, group = paraderosubida),
    size = 1.2
    ) +
  scale_x_datetime(date_labels = "%R") +
  scale_y_continuous(label = scales::comma) +
  scale_color_viridis_d(option = "A", end = 0.8, name = NULL)

p1
```

---

# Correlación 

Es una _métrica_ de asociación _lineal_. Nos ayuda a _cuantificar_ la asociación.

```{r}
set.seed(123)

n <- 100
x <- rnorm(n)
e <- rnorm(n)

pc <- tibble(
  beta  = c(0,  1, 1, -1, -1, 0),
  beta2 = c(0,  0, 0,  1,  0, 1),
  sd    = c(1,  1, 0,  0,  1, 1),
) %>% 
  pmap_df(function(beta = 1, beta2 = 1, sd = 1){
    
    tibble(
      x = x,
      y = beta * x + beta2 * x^2 + sqrt(sd) * e,
      cor = cor(x, y)
    )
    
  }) %>% 
  mutate(
    cor = round(cor, 3),
    cor = str_glue("{cor} ({ percent(cor)})"),
    # cor = percent(cor, accuracy = 0.01),
    cor = fct_inorder(as.character(cor))
    ) %>% 
  ggplot(aes(x, y)) +
  geom_point(alpha = 0.25) +
  facet_wrap(vars(cor), scales = "free") +
  theme(
    axis.text.x = element_text(size = 8),
    axis.text.y = element_text(size = 8),
    )

pc
```

---

# Correlación 

Un valor calculado con dos valores numéricos. Va de -1 a 1.


```{r}
pc +
  geom_smooth(method = "lm", color = "darkred", size = 2, formula = y ~  x)
```

---

# Entonces...

```{r}
df <- d1 %>% 
  spread(paraderosubida, subidas_laboral_promedio) 

lab_dates <- df %>% 
  pull(mediahora) %>% 
  pretty(6)

lab_dates_lbls <- str_extract(lab_dates, "[0-9]{2}:[0-9]{2}")

p2 <-  d1 %>% 
  spread(paraderosubida, subidas_laboral_promedio) %>%  
  ggplot(aes(`LAGUNA SUR`, `PLAZA MAIPU`)) +
  kunstomverse::geom_point2(aes(fill = as.numeric(mediahora)), alpha = 0.8, size = 3) +
  scale_y_continuous(label = scales::comma) +
  scale_x_continuous(label = scales::comma) +
  scale_fill_viridis_c(
    name = NULL,
    breaks = as.numeric(lab_dates), 
    labels = lab_dates_lbls,
    option = "A",
    begin = 0.1,
    end = 0.8
     ) +
  labs(subtitle = str_glue("Correlación { percent(c, , accuracy = 0.01) }"))

p1 | p2 
```


---

# Otro par de estaciones

```{r}
d1 <- data %>% 
  filter(paraderosubida %in% c("UNIVERSIDAD DE CHILE", "PLAZA DE PUENTE ALTO")) 

c <- d1 %>% 
  spread(paraderosubida, subidas_laboral_promedio) %>%
  filter(complete.cases(.)) %>% 
  select(-1) %>%
  as.matrix() %>% 
  cor() %>% 
  as.vector() %>% 
  nth(2)

p1 <- ggplot(d1) +
  geom_line(
    aes(mediahora, subidas_laboral_promedio, color = paraderosubida, group = paraderosubida),
    size = 1.2
    ) +
  scale_x_datetime(date_labels = "%R") +
  scale_y_continuous(label = scales::comma) +
  scale_color_viridis_d(option = "A", end = 0.8, name = NULL)

p2 <-  d1 %>% 
  spread(paraderosubida, subidas_laboral_promedio) %>%  
  ggplot(aes(`UNIVERSIDAD DE CHILE`, `PLAZA DE PUENTE ALTO`)) +
  kunstomverse::geom_point2(aes(fill = as.numeric(mediahora)), alpha = 0.8, size = 3) +
  scale_y_continuous(label = scales::comma) +
  scale_x_continuous(label = scales::comma) +
  scale_fill_viridis_c(
    name = NULL,
    breaks = as.numeric(lab_dates), 
    labels = lab_dates_lbls,
    option = "A",
    begin = 0.1,
    end = 0.8
     ) +
  labs(subtitle = str_glue("Correlación { percent(c, , accuracy = 0.01) }"))

p1 | p2 
```


---

# Correlaciones

<br>


Las correlaciones nos dan una métrica de que tanto se parecen unas estaciones de otras

--

¿Las obtenemos todas y graficamos?

--

- ¿Las obtenemos todas y graficamos?
- ¿Las obtenemos todas y graficamos?
- ¿Las obtenemos todas y graficamos?


---

# Correlaciones

```{r}
dcor <- data %>%
  widyr::pairwise_cor(
    paraderosubida,
    mediahora,
    subidas_laboral_promedio
    )

ncors <- dcor %>% 
  nrow() %>% 
  comma()

nest <- dcor %>% 
  count(item1) %>% 
  nrow() %>% 
  comma()
```

Calculamos con `r nest` estaciones `r ncors` correlaciones.


```{r}
ggplot(dcor) +
  geom_tile(aes(item1, item2, fill = correlation)) + 
  scale_fill_viridis_c(
    option = "A",
    limits = c(-1, 1),
    breaks = seq(-1, 1, length.out = 8),
    labels = percent,
    ) +
  theme(
    axis.text.y = element_text(size = 3),
    axis.text.x = element_text(size = 3, angle = 90, hjust = 1),
    legend.position = "right",
    legend.key.width = unit(0.5, "cm")
    ) +
  labs(x = NULL, y = NULL)
```




---

# Correlaciones

El orden, en este caso, importa.

```{r}
M <- data %>% 
  spread(paraderosubida, subidas_laboral_promedio) %>% 
  select(-1) %>% 
  mutate_all(replace_na, 0) %>% 
  cor()

order <- corrplot::corrMatOrder(M, order = "hclust")
M <- M[order, order]

lvls <- colnames(M)

dcor <- dcor %>% 
  mutate_if(is.character, factor, levels = lvls)

ggplot(dcor) +
  geom_tile(aes(item1, item2, fill = correlation)) + 
  scale_fill_viridis_c(
    option = "A",
    limits = c(-1, 1),
    breaks = seq(-1, 1, length.out = 8),
    labels = percent,
    ) +
  theme(
    axis.text.y = element_text(size = 3),
    axis.text.x = element_text(size = 3, angle = 90, hjust = 1),
    legend.position = "right",
    legend.key.width = unit(0.5, "cm")
    ) +
  labs(x = NULL, y = NULL)
```

---

# Redes y comunidades

```{r}
library(igraph)
library(ggnetwork)

ncors <- 250

dcorf <- dcor %>%
  filter(as.character(item1) < as.character(item2)) %>% 
  arrange(desc(correlation)) %>% 
  mutate(w = correlation*correlation) %>% 
  head(ncors)
```


Considerando las `r ncors` correlaciones más altas realizamos una red donde el peso
del vértice es la correlación y el tamaño es la cantidad de subidas.


```{r}
g <- graph_from_data_frame(dcorf, directed = FALSE)

E(g)$weight <- dcorf$w

wc <- cluster_fast_greedy(g)
nc <- length(unique(membership(wc)))

dvert <- tibble(paraderosubida = V(g)$name) %>% 
  mutate(comm = membership(wc)) %>% 
  left_join(
    data %>%
      group_by(paraderosubida) %>%
      summarise(n = sum(subidas_laboral_promedio)),
    by = "paraderosubida"
    ) %>% 
  left_join(
    data %>%
      group_by(paraderosubida) %>% 
      summarise(tend = cor(seq(1, n()), subidas_laboral_promedio)),
    by = "paraderosubida"
    ) %>% 
  ungroup()

# dvert

V(g)$label <- dvert$paraderosubida
V(g)$size <- dvert$n
V(g)$subidas_totales_miles <- round(dvert$n/1000, 2)
V(g)$comm <- membership(wc)
V(g)$tendencia <- round(dvert$tend, 2)
V(g)$color <- dvert$comm

set.seed(123)

ggnet <- ggnetwork(g)

dfnet2 <- ggnet %>%
  as.matrix() %>%
  as.data.frame() %>%
  tbl_df() %>%
  select(x, y, name, weight, size, color) %>%
  mutate_all(as.character) %>%
  mutate_at(vars(x, y, weight, size), as.numeric) %>%
  filter(is.na(weight))

ggplot(ggnet) + 
  geom_edges(
    aes(-x, -y, size = width, color = factor(comm), xend = -xend, yend = -yend), 
    color = "gray", size = 1, alpha = 0.25
    ) +
  geom_point(
    aes(-x, -y, size = size, color = factor(comm))
    ) +
  ggrepel::geom_text_repel(
    aes(-x, -y, label = name), size = 2,
    data = dfnet2, color = "#666666",
    force = 10,
    family = "main_font"
    ) +
  scale_color_viridis_d() + 
  # theme_void() +
  theme(
    panel.grid.major = element_blank(),
    axis.text.x = element_blank(),
    axis.text.y = element_blank(),
    legend.position = "right"
  ) +
  guides(color = guide_legend(override.aes = list(size = 5))) +
  labs(
    x = NULL,
    y = NULL,
    size = "Subidas",
    color = "Comunidad"
    )
```

---

# Reducción de Dimensionalidad

--
Hasta ahora hemos usado solamente *correlaciones* que miden asociacion lineal 
y no es um indicador necesariamente robusto para usarlo como métrica de distancia.

--

Usaremos todos los datos por estacion y usaremos __UMAP__, un algoritmo 
para _resumir_ toda la información en *2* columnas/variables.

--

Lleva de una tabla con muchas columnas por observación a 2 columnas:

<small><small><small><small><small><small>

.pull-left[
```{r}
nhead <- 10

datas <- data %>% 
  mutate(mediahora = format(mediahora, "%R")) %>% 
  spread(mediahora, subidas_laboral_promedio)

datas <- datas %>% 
  mutate_if(is.numeric, replace_na, 0)

datas %>% 
  select(1:8) %>% 
  head(nhead) %>% 
  knitr::kable(format = "html")
```
] 

.pull-right[
```{r, cache=TRUE}
library(uwot)

um <- umap(datas, verbose = TRUE, n_threads = 3, n_neighbors = 20)

umd <- as.data.frame(um) %>% 
  tbl_df() %>% 
  mutate(paraderosubida = pull(datas, paraderosubida)) %>% 
  select(paraderosubida, everything())

umd %>% 
  head(nhead) %>% 
  knitr::kable(format = "html")
```
]

</small></small></small></small></small></small>

---

# Reducción de Dimensionalidad

```{r}
ggplot(umd) +
  geom_point(aes(V1, V2), alpha = 0.3) +
  ggrepel::geom_text_repel(
    aes(V1, V2, label = paraderosubida),
    data = . %>% sample_n(30),
    size = 3,
    force = 10
    ) 
```

---

# Reducción de Dimensionalidad

```{r}
library(ggdendro)

rownames(umd) <- pull(umd, paraderosubida)

hcd <- hclust(dist(umd))

hc       <- hclust(dist(umd), "ave")           # heirarchal clustering
dendr    <- dendro_data(hc, type="rectangle") # convert for ggplot
clust    <- cutree(hc, k = 4)                    # find 2 clusters
clust.df <- data.frame(label = names(clust), cluster = factor(clust))
dendr[["labels"]] <- merge(dendr[["labels"]], clust.df, by = "label")

ggplot() +
  geom_segment(
    data = segment(dendr),
    aes(x = x, y = y, xend = xend, yend = yend)
    ) +
  geom_text(
    data = label(dendr),
    aes(x, y, label = label, hjust = 1, color = cluster),
    size = 2
  ) +
  coord_flip() +
  scale_color_viridis_d(begin = 0.1, end = 0.8) +
  scale_y_continuous(limits = c(-0.10, NA)) +
  # scale_y_reverse(expand=c(0.2, 0)) +
  theme(
    axis.line.y = element_blank(),
    axis.ticks.y = element_blank(),
    axis.text.y = element_blank(),
    axis.title.y = element_blank(),
    panel.grid.major.y = element_blank(),
    panel.grid = element_blank(),
    legend.position = "none"
  )
```

---

# Reducción de Dimensionalidad

```{r}
umd2 <- umd %>% 
  left_join(clust.df, by = c("paraderosubida" = "label")) 

ggplot(umd2) +
  geom_point(aes(V1, V2, color = cluster), alpha = 0.8) +
  scale_color_viridis_d() +
  ggrepel::geom_text_repel(aes(V1, V2, label = paraderosubida),
                  data = . %>% sample_n(20),
                  size = 3,
                  force = 10) 
```

---

# Finalmente

```{r}
data %>% 
  left_join(umd2 %>% select(paraderosubida, cluster)) %>% 
  ggplot(aes(mediahora, subidas_laboral_promedio)) +
  geom_line(aes(group = paraderosubida), alpha = 0.1, size = 1) +
  geom_smooth(aes(color = cluster), se = FALSE, size = 2) + 
  scale_color_viridis_d() +
  facet_wrap(vars(cluster))
```

